# Importing modules
import tensorflow as tf
import numpy as np
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Flatten, Dense, Activation
import matplotlib.pyplot as plt

# Load MNIST dataset
(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()

# Cast the records into float values
x_train = x_train.astype('float32')
x_test = x_test.astype('float32')

# Normalize image pixel values by dividing by 255
gray_scale = 255.0
x_train /= gray_scale
x_test /= gray_scale
print("Feature matrix:", x_train.shape)
print("Target matrix:", x_test.shape)
print("Feature matrix:", y_train.shape)
print("Target matrix:", y_test.shape)

# Displaying a grid of 100 images from the MNIST dataset
fig, ax = plt.subplots(10, 10, figsize=(10, 10)) # Create 10x10 subplots

k = 0
for i in range(10):
for j in range(10):
ax[i][j].imshow(x_train[k].reshape(28, 28), cmap='gray', aspect='auto')
ax[i][j].axis('off') # Hide axes for clarity
k += 1
plt.show()


# Defining the model
model = Sequential([
# Reshape 28x28 data to a flat vector of 28*28 (784) elements
Flatten(input_shape=(28, 28)),

# Dense layer 1 with 256 neurons and 'sigmoid' activation
Dense(256, activation='sigmoid'),

# Dense layer 2 with 128 neurons and 'sigmoid' activation
Dense(128, activation='sigmoid'),

# Output layer with 10 neurons (for 10 classes) and 'softmax' activation
Dense(10, activation='softmax')
])
model.summary()

model.compile(optimizer='adam',
loss='sparse_categorical_crossentropy',
metrics=['accuracy'])
model.fit(x_train, y_train, epochs=10,
batch_size=2000,
validation_split=0.2)

results = model.evaluate(x_test, y_test, verbose = 0)
print('test loss, test acc:', results)